{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maruanottoni/anaconda3/envs/gce/lib/python3.9/site-packages/torch_geometric/typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/maruanottoni/anaconda3/envs/gce/lib/python3.9/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/maruanottoni/anaconda3/envs/gce/lib/python3.9/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/maruanottoni/anaconda3/envs/gce/lib/python3.9/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import VGAE, GCNConv\n",
    "from torch_geometric.utils import from_networkx, erdos_renyi_graph\n",
    "import networkx as nx\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGAE experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'torch_geometric.nn.models.autoencoder',\n",
       "              '__doc__': 'The Variational Graph Auto-Encoder model from the\\n    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\\n    paper.\\n\\n    Args:\\n        encoder (torch.nn.Module): The encoder module to compute :math:`\\\\mu`\\n            and :math:`\\\\log\\\\sigma^2`.\\n        decoder (torch.nn.Module, optional): The decoder module. If set to\\n            :obj:`None`, will default to the\\n            :class:`torch_geometric.nn.models.InnerProductDecoder`.\\n            (default: :obj:`None`)\\n    ',\n",
       "              '__init__': <function torch_geometric.nn.models.autoencoder.VGAE.__init__(self, encoder: torch.nn.modules.module.Module, decoder: Optional[torch.nn.modules.module.Module] = None)>,\n",
       "              'reparametrize': <function torch_geometric.nn.models.autoencoder.VGAE.reparametrize(self, mu: torch.Tensor, logstd: torch.Tensor) -> torch.Tensor>,\n",
       "              'encode': <function torch_geometric.nn.models.autoencoder.VGAE.encode(self, *args, **kwargs) -> torch.Tensor>,\n",
       "              'kl_loss': <function torch_geometric.nn.models.autoencoder.VGAE.kl_loss(self, mu: Optional[torch.Tensor] = None, logstd: Optional[torch.Tensor] = None) -> torch.Tensor>})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGAE.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv_mu = GCNConv(hidden_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "def generate_correlated_params(n, correlation):\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, correlation], [correlation, 1]]\n",
    "    return np.random.multivariate_normal(mean, cov, n)\n",
    "\n",
    "def generate_graph(n, p):\n",
    "    return nx.erdos_renyi_graph(n, p)\n",
    "\n",
    "def get_embedding(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "    return z.mean(dim=0).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def experiment(num_graphs=200, nodes=50, hidden_channels=32, out_channels=16, correlation=0.5):\n",
    "    print(\"Starting experiment...\")\n",
    "    # Generate correlated parameters\n",
    "    params = generate_correlated_params(num_graphs, correlation)\n",
    "    # Normalize params with sigmoid\n",
    "    params = torch.sigmoid(torch.tensor(params))\n",
    "    print(f\"Generated {num_graphs} pairs of correlated parameters\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Generate graphs and prepare dataset\n",
    "    all_data = []\n",
    "    for i, (p1, _) in enumerate(tqdm(params, desc=\"Generating graphs\")):\n",
    "        g = generate_graph(nodes, p1)\n",
    "        \n",
    "        data = from_networkx(g)\n",
    "        \n",
    "        data.x = torch.tensor(list(dict(g.degree()).values()), dtype=torch.float).view(-1, 1).to(device)\n",
    "        data.edge_index = data.edge_index.to(device)\n",
    "        \n",
    "        all_data.append(data)\n",
    "    \n",
    "    print(f\"Generated {len(all_data)} graphs\")\n",
    "\n",
    "    # Create VGAE model\n",
    "    model = VGAE(Encoder(1, hidden_channels, out_channels)).to(device)\n",
    "\n",
    "    # Save data and model\n",
    "    data_dir = os.path.join('..', 'data')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    torch.save(all_data, os.path.join(data_dir, 'all_data.pt'))\n",
    "    torch.save(model.state_dict(), os.path.join(data_dir, 'model_initial.pt'))\n",
    "    \n",
    "    print(f\"Saved initial data and model to {data_dir}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Train VGAE model on the entire dataset\n",
    "    print(\"Training VGAE model...\")\n",
    "    for epoch in tqdm(range(50), desc=\"Training epochs\"):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for data in all_data:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.encode(data.x, data.edge_index)\n",
    "            loss = model.recon_loss(z, data.edge_index)\n",
    "            loss += (1 / data.num_nodes) * model.kl_loss()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(all_data)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"VGAE model trained\")\n",
    "\n",
    "    # Save trained model\n",
    "    torch.save(model.state_dict(), os.path.join(data_dir, 'model_trained.pt'))\n",
    "    print(f\"Saved trained model to {data_dir}\")\n",
    "\n",
    "    # Get embeddings for all graphs using the trained model\n",
    "    embeddings = []\n",
    "    \n",
    "    print(\"Calculating embeddings...\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(all_data, desc=\"Processing graphs\"):\n",
    "            z = model.encode(data.x, data.edge_index)\n",
    "            emb = z.mean(dim=0).cpu().numpy()\n",
    "            embeddings.append(emb)\n",
    "\n",
    "    # Save embeddings\n",
    "    torch.save(torch.tensor(embeddings), os.path.join(data_dir, 'embeddings.pt'))\n",
    "    print(f\"Saved embeddings as tensor to {data_dir}\")\n",
    "\n",
    "    print(\"Experiment completed.\")\n",
    "\n",
    "print(\"Running experiment...\")\n",
    "experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment...\n",
      "Starting experiment...\n",
      "Generated 200 pairs of correlated parameters\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating graph pairs: 100%|██████████| 200/200 [00:30<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 400 graphs\n",
      "Saved initial data and models to ../data\n",
      "Training VGAE models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:   5%|▌         | 5/100 [01:18<24:21, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss1: 1.6474, Avg Loss2: 1.6556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  10%|█         | 10/100 [02:27<21:07, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Avg Loss1: 1.6402, Avg Loss2: 1.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  15%|█▌        | 15/100 [03:38<19:53, 14.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Avg Loss1: 1.6386, Avg Loss2: 1.6423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  20%|██        | 20/100 [04:47<18:34, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Avg Loss1: 1.6389, Avg Loss2: 1.6424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  25%|██▌       | 25/100 [05:57<17:22, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Avg Loss1: 1.6389, Avg Loss2: 1.6406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  30%|███       | 30/100 [07:06<16:13, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Avg Loss1: 1.6397, Avg Loss2: 1.6405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  35%|███▌      | 35/100 [08:18<15:25, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Avg Loss1: 1.6399, Avg Loss2: 1.6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  40%|████      | 40/100 [09:29<14:19, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Avg Loss1: 1.6401, Avg Loss2: 1.6417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  45%|████▌     | 45/100 [10:39<12:48, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Avg Loss1: 1.6393, Avg Loss2: 1.6395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  50%|█████     | 50/100 [11:53<12:15, 14.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Avg Loss1: 1.6413, Avg Loss2: 1.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  55%|█████▌    | 55/100 [13:06<10:56, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Avg Loss1: 1.6396, Avg Loss2: 1.6398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  60%|██████    | 60/100 [14:20<09:56, 14.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Avg Loss1: 1.6403, Avg Loss2: 1.6402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  65%|██████▌   | 65/100 [15:31<08:18, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Avg Loss1: 1.6402, Avg Loss2: 1.6406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  70%|███████   | 70/100 [16:41<07:00, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Avg Loss1: 1.6402, Avg Loss2: 1.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  75%|███████▌  | 75/100 [17:52<05:51, 14.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Avg Loss1: 1.6403, Avg Loss2: 1.6413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  80%|████████  | 80/100 [19:01<04:39, 13.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Avg Loss1: 1.6395, Avg Loss2: 1.6381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  85%|████████▌ | 85/100 [20:11<03:29, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, Avg Loss1: 1.6382, Avg Loss2: 1.6406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  90%|█████████ | 90/100 [21:22<02:20, 14.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Avg Loss1: 1.6384, Avg Loss2: 1.6407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  95%|█████████▌| 95/100 [22:32<01:09, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Avg Loss1: 1.6414, Avg Loss2: 1.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs: 100%|██████████| 100/100 [23:41<00:00, 14.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Avg Loss1: 1.6423, Avg Loss2: 1.6403\n",
      "VGAE models trained\n",
      "Saved trained models to ../data\n",
      "Calculating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing graphs:   0%|          | 0/400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 116\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m param_corr, emb_corr\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning experiment...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m param_corr, emb_corr \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 98\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m(num_graphs, nodes, hidden_channels, out_channels, correlation)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(all_data, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 98\u001b[0m     emb1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     emb2 \u001b[38;5;241m=\u001b[39m get_embedding(model2, data)\n\u001b[1;32m    100\u001b[0m     embeddings1\u001b[38;5;241m.\u001b[39mappend(emb1)\n",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     23\u001b[0m     z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def experiment(num_graphs=200, nodes=50, hidden_channels=32, out_channels=16, correlation=0.5):\n",
    "    print(\"Starting experiment...\")\n",
    "    # Generate correlated parameters\n",
    "    params = generate_correlated_params(num_graphs, correlation)\n",
    "    # Normalize params with sigmoid\n",
    "    params = torch.sigmoid(torch.tensor(params))\n",
    "    print(f\"Generated {num_graphs} pairs of correlated parameters\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # Uncomment the line below if you want to use MPS (Metal Performance Shaders) on macOS\n",
    "    # device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Generate graphs and prepare dataset\n",
    "    all_data = []\n",
    "    for i, (p1, p2) in enumerate(tqdm(params, desc=\"Generating graph pairs\")):\n",
    "        g1 = generate_graph(nodes, p1)\n",
    "        g2 = generate_graph(nodes, p2)\n",
    "        \n",
    "        data1 = from_networkx(g1)\n",
    "        data2 = from_networkx(g2)\n",
    "        \n",
    "        data1.x = torch.tensor(list(dict(g1.degree()).values()), dtype=torch.float).view(-1, 1).to(device)\n",
    "        data2.x = torch.tensor(list(dict(g2.degree()).values()), dtype=torch.float).view(-1, 1).to(device)\n",
    "        \n",
    "        data1.edge_index = data1.edge_index.to(device)\n",
    "        data2.edge_index = data2.edge_index.to(device)\n",
    "        \n",
    "        all_data.extend([data1, data2])\n",
    "    \n",
    "    print(f\"Generated {len(all_data)} graphs\")\n",
    "\n",
    "    # Create VGAE models\n",
    "    model1 = VGAE(Encoder(1, hidden_channels, out_channels)).to(device)\n",
    "    model2 = VGAE(Encoder(1, hidden_channels, out_channels)).to(device)\n",
    "\n",
    "    # Save data and models\n",
    "    data_dir = os.path.join('..', 'data')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    torch.save(all_data, os.path.join(data_dir, 'all_data.pt'))\n",
    "    torch.save(model1.state_dict(), os.path.join(data_dir, 'model1_initial.pt'))\n",
    "    torch.save(model2.state_dict(), os.path.join(data_dir, 'model2_initial.pt'))\n",
    "    \n",
    "    print(f\"Saved initial data and models to {data_dir}\")\n",
    "\n",
    "    optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
    "\n",
    "    early_stopping1 = EarlyStopping(patience=5)\n",
    "    early_stopping2 = EarlyStopping(patience=5)\n",
    "\n",
    "    # Train VGAE models on the entire dataset\n",
    "    print(\"Training VGAE models...\")\n",
    "    for epoch in tqdm(range(50), desc=\"Training epochs\"):\n",
    "        model1.train()\n",
    "        model2.train()\n",
    "        total_loss1 = 0\n",
    "        total_loss2 = 0\n",
    "        \n",
    "        for data in all_data:\n",
    "            optimizer1.zero_grad()\n",
    "            z1 = model1.encode(data.x, data.edge_index)\n",
    "            loss1 = model1.recon_loss(z1, data.edge_index)\n",
    "            loss1 += (1 / data.num_nodes) * model1.kl_loss()\n",
    "            loss1.backward()\n",
    "            optimizer1.step()\n",
    "            total_loss1 += loss1.item()\n",
    "            \n",
    "            optimizer2.zero_grad()\n",
    "            z2 = model2.encode(data.x, data.edge_index)\n",
    "            loss2 = model2.recon_loss(z2, data.edge_index)\n",
    "            loss2 += (1 / data.num_nodes) * model2.kl_loss()\n",
    "            loss2.backward()\n",
    "            optimizer2.step()\n",
    "            total_loss2 += loss2.item()\n",
    "        \n",
    "        avg_loss1 = total_loss1 / len(all_data)\n",
    "        avg_loss2 = total_loss2 / len(all_data)\n",
    "        \n",
    "        early_stopping1(avg_loss1)\n",
    "        early_stopping2(avg_loss2)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Avg Loss1: {avg_loss1:.4f}, Avg Loss2: {avg_loss2:.4f}\")\n",
    "        \n",
    "        if early_stopping1.early_stop and early_stopping2.early_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    print(\"VGAE models trained\")\n",
    "\n",
    "    # Save trained models\n",
    "    torch.save(model1.state_dict(), os.path.join(data_dir, 'model1_trained.pt'))\n",
    "    torch.save(model2.state_dict(), os.path.join(data_dir, 'model2_trained.pt'))\n",
    "    print(f\"Saved trained models to {data_dir}\")\n",
    "\n",
    "    # Get embeddings for all graphs using the trained models\n",
    "    embeddings1 = []\n",
    "    embeddings2 = []\n",
    "    \n",
    "    print(\"Calculating embeddings...\")\n",
    "    for data in tqdm(all_data, desc=\"Processing graphs\"):\n",
    "        emb1 = get_embedding(model1, data)\n",
    "        emb2 = get_embedding(model2, data)\n",
    "        embeddings1.append(emb1)\n",
    "        embeddings2.append(emb2)\n",
    "\n",
    "    # Save embeddings\n",
    "    torch.save(torch.tensor(embeddings1), os.path.join(data_dir, 'embeddings1.pt'))\n",
    "    torch.save(torch.tensor(embeddings2), os.path.join(data_dir, 'embeddings2.pt'))\n",
    "    print(f\"Saved embeddings as tensors to {data_dir}\")\n",
    "\n",
    "    print(\"Calculating correlations...\")\n",
    "    # Calculate correlations\n",
    "    param_corr, _ = spearmanr(params.cpu().numpy()[:, 0], params.cpu().numpy()[:, 1])\n",
    "    emb_corr, _ = spearmanr(np.array(embeddings1).flatten(), np.array(embeddings2).flatten())\n",
    "\n",
    "    return param_corr, emb_corr\n",
    "\n",
    "print(\"Running experiment...\")\n",
    "param_corr, emb_corr = experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running processing...\n",
      "Loading data and models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2332/4211892069.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  all_data = torch.load(os.path.join(data_dir, 'all_data.pt'))\n",
      "/tmp/ipykernel_2332/4211892069.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model1.load_state_dict(torch.load(os.path.join(data_dir, 'model1_trained.pt')))\n",
      "/tmp/ipykernel_2332/4211892069.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2.load_state_dict(torch.load(os.path.join(data_dir, 'model2_trained.pt')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400 graphs\n",
      "Using device: cuda\n",
      "Models loaded successfully\n",
      "Calculating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing graphs:   2%|▏         | 9/400 [00:00<00:04, 79.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing graphs: 100%|██████████| 400/400 [00:04<00:00, 84.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings as tensors to ../data\n",
      "Calculating correlations...\n",
      "Embedding correlation: 0.22352941176470587\n",
      "Processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "    return z.mean(dim=0).cpu().numpy()\n",
    "\n",
    "def load_and_process():\n",
    "    print(\"Loading data and models...\")\n",
    "    data_dir = os.path.join('..', 'data')\n",
    "    \n",
    "    # Load data\n",
    "    all_data = torch.load(os.path.join(data_dir, 'all_data.pt'))\n",
    "    print(f\"Loaded {len(all_data)} graphs\")\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load models\n",
    "    model1 = VGAE(Encoder(1, 32, 16)).to(device)\n",
    "    model2 = VGAE(Encoder(1, 32, 16)).to(device)\n",
    "    \n",
    "    model1.load_state_dict(torch.load(os.path.join(data_dir, 'model1_trained.pt')))\n",
    "    model2.load_state_dict(torch.load(os.path.join(data_dir, 'model2_trained.pt')))\n",
    "    \n",
    "    print(\"Models loaded successfully\")\n",
    "\n",
    "    # Calculate embeddings\n",
    "    embeddings1 = []\n",
    "    embeddings2 = []\n",
    "    \n",
    "    print(\"Calculating embeddings...\")\n",
    "    for data in tqdm(all_data, desc=\"Processing graphs\"):\n",
    "        data = data.to(device)\n",
    "        emb1 = get_embedding(model1, data)\n",
    "        emb2 = get_embedding(model2, data)\n",
    "        embeddings1.append(emb1)\n",
    "        embeddings2.append(emb2)\n",
    "\n",
    "    # Save embeddings\n",
    "    torch.save(torch.tensor(embeddings1), os.path.join(data_dir, 'embeddings1.pt'))\n",
    "    torch.save(torch.tensor(embeddings2), os.path.join(data_dir, 'embeddings2.pt'))\n",
    "    print(f\"Saved embeddings as tensors to {data_dir}\")\n",
    "\n",
    "\n",
    "    print(\"Calculating correlations...\")\n",
    "    # Calculate correlations\n",
    "    emb_corr, _ = spearmanr(np.array(embeddings1).flatten(), np.array(embeddings2).flatten())\n",
    "\n",
    "    return emb_corr\n",
    "\n",
    "print(\"Running processing...\")\n",
    "emb_corr = load_and_process()\n",
    "\n",
    "print(f\"Embedding correlation: {emb_corr}\")\n",
    "print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrum baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment...\n",
      "Starting experiment...\n",
      "Generated 200 pairs of correlated parameters\n",
      "Generating graphs and calculating spectral radii...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing graph pairs:  48%|████▊     | 95/200 [00:01<00:01, 70.98it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "import networkx as nx\n",
    "\n",
    "def generate_correlated_params(num_graphs, correlation):\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, correlation], [correlation, 1]]\n",
    "    return np.random.multivariate_normal(mean, cov, num_graphs)\n",
    "\n",
    "def generate_graph(nodes, p):\n",
    "    return nx.erdos_renyi_graph(nodes, p)\n",
    "\n",
    "def get_spectral_radius(graph):\n",
    "    adjacency_matrix = nx.adjacency_matrix(graph).todense()\n",
    "    eigenvalues = np.linalg.eigvals(adjacency_matrix)\n",
    "    return np.max(np.abs(eigenvalues))\n",
    "\n",
    "def experiment(num_graphs=200, nodes=50, correlation=0.5):\n",
    "    print(\"Starting experiment...\")\n",
    "    # Generate correlated parameters\n",
    "    params = generate_correlated_params(num_graphs, correlation)\n",
    "    # Normalize params with sigmoid\n",
    "    params = torch.sigmoid(torch.tensor(params))\n",
    "    print(f\"Generated {num_graphs} pairs of correlated parameters\")\n",
    "\n",
    "    # Generate graphs and calculate spectral radii\n",
    "    spectral_radii1 = []\n",
    "    spectral_radii2 = []\n",
    "\n",
    "    print(\"Generating graphs and calculating spectral radii...\")\n",
    "    for p1, p2 in tqdm(params, desc=\"Processing graph pairs\"):\n",
    "        g1 = generate_graph(nodes, p1.item())\n",
    "        g2 = generate_graph(nodes, p2.item())\n",
    "\n",
    "        sr1 = get_spectral_radius(g1)\n",
    "        sr2 = get_spectral_radius(g2)\n",
    "\n",
    "        spectral_radii1.append(sr1)\n",
    "        spectral_radii2.append(sr2)\n",
    "\n",
    "    print(f\"Calculated spectral radii for {num_graphs} graph pairs\")\n",
    "\n",
    "    # Save data\n",
    "    data_dir = os.path.join('..', 'data')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    np.save(os.path.join(data_dir, 'params.npy'), params.numpy())\n",
    "    np.save(os.path.join(data_dir, 'spectral_radii1.npy'), np.array(spectral_radii1))\n",
    "    np.save(os.path.join(data_dir, 'spectral_radii2.npy'), np.array(spectral_radii2))\n",
    "    \n",
    "    print(f\"Saved parameters and spectral radii to {data_dir}\")\n",
    "\n",
    "    print(\"Calculating correlations...\")\n",
    "    # Calculate correlations\n",
    "    param_corr, _ = spearmanr(params.numpy()[:, 0], params.numpy()[:, 1])\n",
    "    sr_corr, _ = spearmanr(spectral_radii1, spectral_radii2)\n",
    "\n",
    "    return param_corr, sr_corr\n",
    "\n",
    "print(\"Running experiment...\")\n",
    "param_corr, sr_corr = experiment()\n",
    "\n",
    "print(f\"Parameter correlation: {param_corr}\")\n",
    "print(f\"Spectral radius correlation: {sr_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
