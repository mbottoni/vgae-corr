{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maruanottoni/anaconda3/envs/gce/lib/python3.9/site-packages/torch_geometric/typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/maruanottoni/anaconda3/envs/gce/lib/python3.9/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/maruanottoni/anaconda3/envs/gce/lib/python3.9/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/maruanottoni/anaconda3/envs/gce/lib/python3.9/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import VGAE, GCNConv\n",
    "from torch_geometric.utils import from_networkx, erdos_renyi_graph\n",
    "import networkx as nx\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGAE experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'torch_geometric.nn.models.autoencoder',\n",
       "              '__doc__': 'The Variational Graph Auto-Encoder model from the\\n    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\\n    paper.\\n\\n    Args:\\n        encoder (torch.nn.Module): The encoder module to compute :math:`\\\\mu`\\n            and :math:`\\\\log\\\\sigma^2`.\\n        decoder (torch.nn.Module, optional): The decoder module. If set to\\n            :obj:`None`, will default to the\\n            :class:`torch_geometric.nn.models.InnerProductDecoder`.\\n            (default: :obj:`None`)\\n    ',\n",
       "              '__init__': <function torch_geometric.nn.models.autoencoder.VGAE.__init__(self, encoder: torch.nn.modules.module.Module, decoder: Optional[torch.nn.modules.module.Module] = None)>,\n",
       "              'reparametrize': <function torch_geometric.nn.models.autoencoder.VGAE.reparametrize(self, mu: torch.Tensor, logstd: torch.Tensor) -> torch.Tensor>,\n",
       "              'encode': <function torch_geometric.nn.models.autoencoder.VGAE.encode(self, *args, **kwargs) -> torch.Tensor>,\n",
       "              'kl_loss': <function torch_geometric.nn.models.autoencoder.VGAE.kl_loss(self, mu: Optional[torch.Tensor] = None, logstd: Optional[torch.Tensor] = None) -> torch.Tensor>})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGAE.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv_mu = GCNConv(hidden_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "\n",
    "def generate_correlated_params(n, correlation):\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, correlation], [correlation, 1]]\n",
    "    return np.random.multivariate_normal(mean, cov, n)\n",
    "\n",
    "def generate_graph(n, p):\n",
    "    return nx.erdos_renyi_graph(n, p)\n",
    "\n",
    "def get_embedding(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "    return z.mean(dim=0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment...\n",
      "Starting experiment...\n",
      "Generated 200 pairs of correlated parameters\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating graph pairs: 100%|██████████| 200/200 [00:30<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 400 graphs\n",
      "Saved initial data and models to ../data\n",
      "Training VGAE models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:   5%|▌         | 5/100 [01:18<24:21, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss1: 1.6474, Avg Loss2: 1.6556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  10%|█         | 10/100 [02:27<21:07, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Avg Loss1: 1.6402, Avg Loss2: 1.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  15%|█▌        | 15/100 [03:38<19:53, 14.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Avg Loss1: 1.6386, Avg Loss2: 1.6423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  19%|█▉        | 19/100 [04:33<18:49, 13.95s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def experiment(num_graphs=200, nodes=50, hidden_channels=32, out_channels=16, correlation=0.5):\n",
    "    print(\"Starting experiment...\")\n",
    "    # Generate correlated parameters\n",
    "    params = generate_correlated_params(num_graphs, correlation)\n",
    "    # Normalize params with sigmoid\n",
    "    params = torch.sigmoid(torch.tensor(params))\n",
    "    print(f\"Generated {num_graphs} pairs of correlated parameters\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # Uncomment the line below if you want to use MPS (Metal Performance Shaders) on macOS\n",
    "    # device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Generate graphs and prepare dataset\n",
    "    all_data = []\n",
    "    for i, (p1, p2) in enumerate(tqdm(params, desc=\"Generating graph pairs\")):\n",
    "        g1 = generate_graph(nodes, p1)\n",
    "        g2 = generate_graph(nodes, p2)\n",
    "        \n",
    "        data1 = from_networkx(g1)\n",
    "        data2 = from_networkx(g2)\n",
    "        \n",
    "        data1.x = torch.tensor(list(dict(g1.degree()).values()), dtype=torch.float).view(-1, 1).to(device)\n",
    "        data2.x = torch.tensor(list(dict(g2.degree()).values()), dtype=torch.float).view(-1, 1).to(device)\n",
    "        \n",
    "        data1.edge_index = data1.edge_index.to(device)\n",
    "        data2.edge_index = data2.edge_index.to(device)\n",
    "        \n",
    "        all_data.extend([data1, data2])\n",
    "    \n",
    "    print(f\"Generated {len(all_data)} graphs\")\n",
    "\n",
    "    # Create VGAE models\n",
    "    model1 = VGAE(Encoder(1, hidden_channels, out_channels)).to(device)\n",
    "    model2 = VGAE(Encoder(1, hidden_channels, out_channels)).to(device)\n",
    "\n",
    "    # Save data and models\n",
    "    data_dir = os.path.join('..', 'data')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    torch.save(all_data, os.path.join(data_dir, 'all_data.pt'))\n",
    "    torch.save(model1.state_dict(), os.path.join(data_dir, 'model1_initial.pt'))\n",
    "    torch.save(model2.state_dict(), os.path.join(data_dir, 'model2_initial.pt'))\n",
    "    \n",
    "    print(f\"Saved initial data and models to {data_dir}\")\n",
    "\n",
    "    optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
    "\n",
    "    # Train VGAE models on the entire dataset\n",
    "    print(\"Training VGAE models...\")\n",
    "    for epoch in tqdm(range(100), desc=\"Training epochs\"):\n",
    "        model1.train()\n",
    "        model2.train()\n",
    "        total_loss1 = 0\n",
    "        total_loss2 = 0\n",
    "        \n",
    "        for data in all_data:\n",
    "            optimizer1.zero_grad()\n",
    "            z1 = model1.encode(data.x, data.edge_index)\n",
    "            loss1 = model1.recon_loss(z1, data.edge_index)\n",
    "            loss1 += (1 / data.num_nodes) * model1.kl_loss()\n",
    "            loss1.backward()\n",
    "            optimizer1.step()\n",
    "            total_loss1 += loss1.item()\n",
    "            \n",
    "            optimizer2.zero_grad()\n",
    "            z2 = model2.encode(data.x, data.edge_index)\n",
    "            loss2 = model2.recon_loss(z2, data.edge_index)\n",
    "            loss2 += (1 / data.num_nodes) * model2.kl_loss()\n",
    "            loss2.backward()\n",
    "            optimizer2.step()\n",
    "            total_loss2 += loss2.item()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Avg Loss1: {total_loss1/len(all_data):.4f}, Avg Loss2: {total_loss2/len(all_data):.4f}\")\n",
    "\n",
    "    print(\"VGAE models trained\")\n",
    "\n",
    "    # Save trained models\n",
    "    torch.save(model1.state_dict(), os.path.join(data_dir, 'model1_trained.pt'))\n",
    "    torch.save(model2.state_dict(), os.path.join(data_dir, 'model2_trained.pt'))\n",
    "    print(f\"Saved trained models to {data_dir}\")\n",
    "\n",
    "    # Get embeddings for all graphs using the trained models\n",
    "    embeddings1 = []\n",
    "    embeddings2 = []\n",
    "    \n",
    "    print(\"Calculating embeddings...\")\n",
    "    for data in tqdm(all_data, desc=\"Processing graphs\"):\n",
    "        emb1 = get_embedding(model1, data)\n",
    "        emb2 = get_embedding(model2, data)\n",
    "        embeddings1.append(emb1)\n",
    "        embeddings2.append(emb2)\n",
    "\n",
    "    # Save embeddings\n",
    "    np.save(os.path.join(data_dir, 'embeddings1.npy'), np.array(embeddings1))\n",
    "    np.save(os.path.join(data_dir, 'embeddings2.npy'), np.array(embeddings2))\n",
    "    print(f\"Saved embeddings to {data_dir}\")\n",
    "\n",
    "    print(\"Calculating correlations...\")\n",
    "    # Calculate correlations\n",
    "    param_corr, _ = spearmanr(params.cpu().numpy()[:, 0], params.cpu().numpy()[:, 1])\n",
    "    emb_corr, _ = spearmanr(np.array(embeddings1).flatten(), np.array(embeddings2).flatten())\n",
    "\n",
    "    return param_corr, emb_corr\n",
    "\n",
    "print(\"Running experiment...\")\n",
    "param_corr, emb_corr = experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter correlation: 0.437911947798695\n",
      "Embedding correlation: -0.4264705882352941\n",
      "Experiment completed.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameter correlation: {param_corr}\")\n",
    "print(f\"Embedding correlation: {emb_corr}\")\n",
    "print(\"Experiment completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrum baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "import networkx as nx\n",
    "\n",
    "def generate_correlated_params(num_graphs, correlation):\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, correlation], [correlation, 1]]\n",
    "    return np.random.multivariate_normal(mean, cov, num_graphs)\n",
    "\n",
    "def generate_graph(nodes, p):\n",
    "    return nx.erdos_renyi_graph(nodes, p)\n",
    "\n",
    "def get_spectral_radius(graph):\n",
    "    adjacency_matrix = nx.adjacency_matrix(graph).todense()\n",
    "    eigenvalues = np.linalg.eigvals(adjacency_matrix)\n",
    "    return np.max(np.abs(eigenvalues))\n",
    "\n",
    "def experiment(num_graphs=200, nodes=50, correlation=0.5):\n",
    "    print(\"Starting experiment...\")\n",
    "    # Generate correlated parameters\n",
    "    params = generate_correlated_params(num_graphs, correlation)\n",
    "    # Normalize params with sigmoid\n",
    "    params = torch.sigmoid(torch.tensor(params))\n",
    "    print(f\"Generated {num_graphs} pairs of correlated parameters\")\n",
    "\n",
    "    # Generate graphs and calculate spectral radii\n",
    "    spectral_radii1 = []\n",
    "    spectral_radii2 = []\n",
    "\n",
    "    print(\"Generating graphs and calculating spectral radii...\")\n",
    "    for p1, p2 in tqdm(params, desc=\"Processing graph pairs\"):\n",
    "        g1 = generate_graph(nodes, p1.item())\n",
    "        g2 = generate_graph(nodes, p2.item())\n",
    "\n",
    "        sr1 = get_spectral_radius(g1)\n",
    "        sr2 = get_spectral_radius(g2)\n",
    "\n",
    "        spectral_radii1.append(sr1)\n",
    "        spectral_radii2.append(sr2)\n",
    "\n",
    "    print(f\"Calculated spectral radii for {num_graphs} graph pairs\")\n",
    "\n",
    "    # Save data\n",
    "    data_dir = os.path.join('..', 'data')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    np.save(os.path.join(data_dir, 'params.npy'), params.numpy())\n",
    "    np.save(os.path.join(data_dir, 'spectral_radii1.npy'), np.array(spectral_radii1))\n",
    "    np.save(os.path.join(data_dir, 'spectral_radii2.npy'), np.array(spectral_radii2))\n",
    "    \n",
    "    print(f\"Saved parameters and spectral radii to {data_dir}\")\n",
    "\n",
    "    print(\"Calculating correlations...\")\n",
    "    # Calculate correlations\n",
    "    param_corr, _ = spearmanr(params.numpy()[:, 0], params.numpy()[:, 1])\n",
    "    sr_corr, _ = spearmanr(spectral_radii1, spectral_radii2)\n",
    "\n",
    "    return param_corr, sr_corr\n",
    "\n",
    "print(\"Running experiment...\")\n",
    "param_corr, sr_corr = experiment()\n",
    "\n",
    "print(f\"Parameter correlation: {param_corr}\")\n",
    "print(f\"Spectral radius correlation: {sr_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
